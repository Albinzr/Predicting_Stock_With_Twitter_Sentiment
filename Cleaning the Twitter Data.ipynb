{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import wordnet\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>947702253313495045</td>\n",
       "      <td>Tesla $TSLA Rating Increased to Hold at ValuEn...</td>\n",
       "      <td>2018-01-01 00:33:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>947702742264569857</td>\n",
       "      <td>Tesla $TSLA Rating Increased to Hold at ValuEn...</td>\n",
       "      <td>2018-01-01 00:35:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>947709627394748416</td>\n",
       "      <td>Horseman Capital Management LTD Increases Posi...</td>\n",
       "      <td>2018-01-01 01:02:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>947712900377976832</td>\n",
       "      <td>Tesla INC (TSLA) Holding Lifted by Horseman Ca...</td>\n",
       "      <td>2018-01-01 01:15:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>947732179253170177</td>\n",
       "      <td>Insider Selling: Tesla Inc (NASDAQ:TSLA) VP Se...</td>\n",
       "      <td>2018-01-01 02:32:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                              tweet  \\\n",
       "0  947702253313495045  Tesla $TSLA Rating Increased to Hold at ValuEn...   \n",
       "1  947702742264569857  Tesla $TSLA Rating Increased to Hold at ValuEn...   \n",
       "2  947709627394748416  Horseman Capital Management LTD Increases Posi...   \n",
       "3  947712900377976832  Tesla INC (TSLA) Holding Lifted by Horseman Ca...   \n",
       "4  947732179253170177  Insider Selling: Tesla Inc (NASDAQ:TSLA) VP Se...   \n",
       "\n",
       "             date_time  \n",
       "0  2018-01-01 00:33:19  \n",
       "1  2018-01-01 00:35:15  \n",
       "2  2018-01-01 01:02:37  \n",
       "3  2018-01-01 01:15:37  \n",
       "4  2018-01-01 02:32:14  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in and preview 'tesla_tweets.csv'\n",
    "\n",
    "tweets = pd.read_csv('tesla_tweets.csv', engine='python')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 213213 entries, 0 to 213212\n",
      "Data columns (total 3 columns):\n",
      "id           213213 non-null object\n",
      "tweet        213213 non-null object\n",
      "date_time    213153 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Examine datatypes inside tweets\n",
    "\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date_time column into datetime stamp\n",
    "\n",
    "tweets.date_time = pd.to_datetime(tweets.date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, tweet, date_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "tweets[tweets.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets[tweets.tweet.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean & Tokenize Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(dataframe):\n",
    "    # Add whitespace to the end of every tweet\n",
    "    dataframe['clean_tweet'] = dataframe.tweet.map(lambda x: x + \" \") \n",
    "    # Remove http links\n",
    "    dataframe.clean_tweet = dataframe.clean_tweet.map(lambda x: re.sub(r'http.*', '', x))\n",
    "    # Remove special characters and numbers\n",
    "    dataframe.clean_tweet = dataframe.clean_tweet.map(lambda x: re.sub(r\"[^a-zA-Z#]\", ' ', x))\n",
    "    # Lowercase all tweets\n",
    "    dataframe.clean_tweet = dataframe.clean_tweet.map(lambda x: x.lower())\n",
    "    #Tokenize tweets and remove stop words\n",
    "    stopword_list = stopwords.words('english')\n",
    "    for i in range(len(dataframe.clean_tweet)):\n",
    "        tokens = word_tokenize(dataframe.clean_tweet[i])\n",
    "        clean_tokens = [w for w in tokens if w not in stopword_list]\n",
    "        dataframe.clean_tweet[i] = clean_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikadauria/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date_time</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>947702253313495045</td>\n",
       "      <td>Tesla $TSLA Rating Increased to Hold at ValuEn...</td>\n",
       "      <td>2018-01-01 00:33:19</td>\n",
       "      <td>[tesla, tsla, rating, increased, hold, valueng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>947702742264569857</td>\n",
       "      <td>Tesla $TSLA Rating Increased to Hold at ValuEn...</td>\n",
       "      <td>2018-01-01 00:35:15</td>\n",
       "      <td>[tesla, tsla, rating, increased, hold, valueng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>947709627394748416</td>\n",
       "      <td>Horseman Capital Management LTD Increases Posi...</td>\n",
       "      <td>2018-01-01 01:02:37</td>\n",
       "      <td>[horseman, capital, management, ltd, increases...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>947712900377976832</td>\n",
       "      <td>Tesla INC (TSLA) Holding Lifted by Horseman Ca...</td>\n",
       "      <td>2018-01-01 01:15:37</td>\n",
       "      <td>[tesla, inc, tsla, holding, lifted, horseman, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>947732179253170177</td>\n",
       "      <td>Insider Selling: Tesla Inc (NASDAQ:TSLA) VP Se...</td>\n",
       "      <td>2018-01-01 02:32:14</td>\n",
       "      <td>[insider, selling, tesla, inc, nasdaq, tsla, v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                              tweet  \\\n",
       "0  947702253313495045  Tesla $TSLA Rating Increased to Hold at ValuEn...   \n",
       "1  947702742264569857  Tesla $TSLA Rating Increased to Hold at ValuEn...   \n",
       "2  947709627394748416  Horseman Capital Management LTD Increases Posi...   \n",
       "3  947712900377976832  Tesla INC (TSLA) Holding Lifted by Horseman Ca...   \n",
       "4  947732179253170177  Insider Selling: Tesla Inc (NASDAQ:TSLA) VP Se...   \n",
       "\n",
       "            date_time                                        clean_tweet  \n",
       "0 2018-01-01 00:33:19  [tesla, tsla, rating, increased, hold, valueng...  \n",
       "1 2018-01-01 00:35:15  [tesla, tsla, rating, increased, hold, valueng...  \n",
       "2 2018-01-01 01:02:37  [horseman, capital, management, ltd, increases...  \n",
       "3 2018-01-01 01:15:37  [tesla, inc, tsla, holding, lifted, horseman, ...  \n",
       "4 2018-01-01 02:32:14  [insider, selling, tesla, inc, nasdaq, tsla, v...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets(tweets)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['insider',\n",
       " 'selling',\n",
       " 'tesla',\n",
       " 'inc',\n",
       " 'nasdaq',\n",
       " 'tsla',\n",
       " 'vp',\n",
       " 'sells',\n",
       " 'shares',\n",
       " 'stock']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.clean_tweet[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tweet(tweets):\n",
    "    \n",
    "    for i in range(len(tweets)):\n",
    "        # Pos-tag each word in tweet\n",
    "        for word in [tweets[i]]:\n",
    "            pos_tag_list = nltk.pos_tag(word)\n",
    "        # Convert pos-tag to be wordnet compliant\n",
    "        wordnet_tags = []\n",
    "        for j in pos_tag_list:\n",
    "            # Adjective\n",
    "            if j[1].startswith('J'):\n",
    "                wordnet_tags.append(wordnet.ADJ)\n",
    "            # Noun\n",
    "            elif j[1].startswith('N'):\n",
    "                wordnet_tags.append(wordnet.NOUN)\n",
    "            # Adverb\n",
    "            elif j[1].startswith('R'):\n",
    "                wordnet_tags.append(wordnet.ADV)\n",
    "            # Verb\n",
    "            elif j[1].startswith('V'):\n",
    "                wordnet_tags.append(wordnet.VERB)\n",
    "            # Default to noun\n",
    "            else:\n",
    "                wordnet_tags.append(wordnet.NOUN)\n",
    "        # Lemmatize each word in tweet\n",
    "        lem_words = []\n",
    "        for k in range(len(tweets[i])):\n",
    "            lem_words.append(lemmatizer.lemmatize(tweets[i][k], pos=wordnet_tags[k]))\n",
    "        lem_tweet = ' '.join(lem_words)\n",
    "        tweets[i] = lem_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikadauria/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lemmatize_tweet(tweets.clean_tweet)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.clean_tweet[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example = dataframe.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most common words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the tweets into a single string\n",
    "all_words_string = ' '.join([tweet for tweet in tweets.clean_tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot WorldCloud\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=20, max_font_size=200).generate(all_words_string)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all the words in the dataframe\n",
    "\n",
    "all_words_list = all_words_string.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the frequency of each word in the dataframe\n",
    "\n",
    "word_freq = nltk.FreqDist(all_words_list)\n",
    "freq_df = pd.DataFrame({'Word': list(word_freq.keys()), 'Count': list(word_freq.values())}).sort_values(by=['Count'], ascending=False)\n",
    "freq_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of most frequent words\n",
    "\n",
    "freq_df = freq_df.nlargest(columns=\"Count\", n = 10) \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=freq_df, x= \"Word\", y = \"Count\")\n",
    "ax.set(ylabel = 'Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What time of day are there the most Tesla tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What day of the week has the most Tesla tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What day of the year had the most tweets about Tesla?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Cleaned Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'/Users/erikadauria/Flatiron/Projects/Tesla_Twitter_Sentiment_Analysis/cleaned_tweets.csv'\n",
    "\n",
    "daily_sentiment.to_csv(filepath, header=True)\n",
    "\n",
    "test = pd.read_csv('cleaned_tweets.csv')\n",
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
